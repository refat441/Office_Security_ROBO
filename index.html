<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Representative Assistant ROBO</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <link rel="stylesheet" href="style.css">

</head>
<body style="background-color: #eef4f7;">
    <!-- nav start -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top">
        <a class="navbar-brand" href="#">Representative Assistant ROBO</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-center font-weight-bold" id="navbarNav">
        <ul class="navbar-nav">
            <li class="nav-item">
            <a class="nav-link" href="#home">Home </a>
            </li>
            <li class="nav-item">
            <a class="nav-link" href="#Project_Details">Project Details</a>
            </li>
            <li class="nav-item">
            <a class="nav-link" href="#Paper_Review">Paper Review</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#team">Team</a>
            </li>
        </ul>
        </div>
    </nav>
    <!-- nav end  -->
    <h1 class="text-center mb-5" id="home">/h1>
    <!-- home carousel start -->
    <div class="text-center pt-5 pb-2" id="home">
        <h1>Wealcome</h1>
    </div>
<div class="container">
    <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
        <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
        </ol>
        <div class="carousel-inner">
            <div class="carousel-item active">
                <img src="https://images.unsplash.com/photo-1485827404703-89b55fcc595e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
            <div class="carousel-item">
                <img src="https://images.unsplash.com/photo-1563968743333-044cef800494?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1958&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
            <div class="carousel-item">
                <img src="https://images.unsplash.com/photo-1518314916381-77a37c2a49ae?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2071&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
        </div>
        <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
        </a>
    </div>
</div>
       <!-- home carousel end -->
       
       <!-- project Details  -->
    <div class=" mt-5" id="Project_Details">
        <h1 >Project Details</h1>
    </div>
    <div class="container mt-5 mb-5 project-details">
        <div class="row">
        <div class="col-sm-6">
            <h1>Representative Assistant Robo</h1>
            <p>
                Introducing our cutting-edge University Assistant Robot, designed to streamline and enhance the student experience on campus. This innovative robot is equipped with a vast array of knowledge about the university's infrastructure and resources. <br>

                Need directions to the BC building, registration office, library, or any other key location? Our robot has you covered. Simply ask, and it will promptly provide clear and accurate directions. <br>
                
                Looking for information about clubs, labs, or financial applications? Our robot is a treasure trove of data, ready to share details about the vibrant club scene, state-of-the-art labs, and the seamless financial process. <br>
                
                Worried about missing the semester fee deadline? Our robot will keep you informed about important dates, ensuring you never miss a deadline. <br>
                
                With its friendly interface and comprehensive knowledge base, the University Assistant Robot is here to make your university journey smoother and more informed. Ask away, and let the robot guide you through your academic adventure.
            </p>
        </div>
        <div class="col-sm-6">
            <img src="img\Firefly Background university campus , a girl talk with robot 82537.jpg" style="width: 100%; height: 100%;" alt="">
        </div>
        </div>
    </div>
    <!-- project Details End-->

    <!-- paper Review Start  -->
    <div class="text-center mt-5 pb-3" id="Paper_Review">
        <h1>Paper Review</h1>
    </div>

    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12">       
                <ul class="nav nav-pills ml-3">
                    <li class="active"><a type="button" class="btn btn-outline-primary border-0 m-2" data-toggle="pill" href="#person1">Rose Chowdhury Ritu</a></li>
                    <li><a  type="button" class="btn btn-outline-primary border-0 m-2" data-toggle="pill" href="#person2">REFAT AHMED BHUIYAN</a></li>
                    <li><a  type="button" class="btn btn-outline-primary border-0 m-2" data-toggle="pill" href="#person3">Md Nakibul Islam</a></li>
                </ul>
    
                <hr>  
    
                <div class="tab-content">
                    <div id="person1" class="tab-pane fade in active container-fluid">
                        <h3>Paper Title: Kinematics Analysis of a quadruped robot</h3>
                        <H4>Introduction</H4>
                        <p>
                            In this study, there are mathematical derivations provided  for forward and Inverse kinematics to determine the robots' positions and joint angles briefly. In this study, the researchers have analyzed and derived the forward and inverse kinematics of the quadruped robots and verified their correlation using Python Programming and Pybullet Physics to determine the robot’s leg motion.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>Md.Hasibur Rahman,  Md.Mazharul Islam, Md.Fayed Al Monir, Saadia Binte Alam,  Ruzvelt, Md.Mijanur Rahman, Rubaiyat Islam.</p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/361466674_Kinematics_analysis_of_a_quadruped_robot_Simulation_and_Evaluation "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            A quadruped robot consists of four legs with a rigid body where each leg has three degrees of freedom and there are three joints : coxa joint, femur joint, and tibia joint. The frame-to-frame rotation and translation matrices are solved to find the forward kinematics in order to achieve the end-effector positions. Inverse kinematics gives the different joint angles of the quadruped robot leg and the end effectors value are used to determine the joint angles.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            After deriving the forward kinematics and inverse kinematics, the correlation between them was verified using mathematical coding in python and Pybullet Physics engines and an algorithm in python was developed where joint angle values are used to get the end effector values and the goal of the paper is successfully achieved by deriving the kinematic equation for the quadruped robot which defines the position, orientation, and movement of the robot.
                        </p>
                        <hr>
                        <h3>Paper Title: Analysis of a Smart Bag Reminder System</h3>
                        <H4 class="mt-3">Introduction</H4>
                        <p>
                            It is important to keep track of many details when caring for a newborn such as making sure to pack all necessary items when leaving the house with a newborn. This paper showed a light-feedback reminder bag and a light-sound feedback reminder bag that use a pressure sensor to remind parents when anything is missing from the bag. A user study with 13 participants was conducted with these two reminder bags.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Md Farhad Hossain, Mengru Xue, Yuqi Hu,  Mohammad Shidujaman.
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/372224060_Design_and_Performance_Analysis_of_a_Smart_Bag_Reminder_System_for_Parents
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The system works by using an Arduino installing a pressure sensor module, an LED light in each of the bag’s pockets, and a speaker and along with the different light feedback from different pockets, the speaker also gives different sound feedback. As soon as the pressure sensor determines that objects have been pushed against it, the light and sound feedback will become active. The bag uses a modular pressure sensor that is readily detachable, and parents can choose the number of pockets that can be utilized and , the audio feedback can be customized according to their preferences, and they can label the front of each pocket with the items they use most often. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The result of this research showed that the light-sound feedback facilitates parent reminders better than light feedback. The largest number of participants displayed enjoyment of the task with a light-sound prototype through the use of a smile. The parents realized that  it was a sound feedback with light, and that when they packaged things, the audio feedback related to the items was delivered when they were packaging and so the  sound feedback helped them move more quickly and  receiving sound feedback assisted them in recognizing what they were packing as  they didn’t have to double-check what they put in the bag since the sound feedback helped them identify the items
                        </p>
                    </div>
                    <div id="person2" class="tab-pane fade">
                        <h3>Paper Title:  A study on the Behavioral Gesture of Social Robots.</h3>
                        <H4>Introduction</H4>
                        <p>
                            This research designed  four different greeting gestures for the NAO robot based on human’s greeting custom and conducted a user experiment in which participants from different countries interact with the robot for a designated recommendation task and the research investigated how cultural familiarity affects acceptance of an agent’s recommendation. 20 participants from four different countries, China, Bangladesh, Japan and Thailand , participated in the experiment. 
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Mohammad Shidujaman,  Haipeng Mi, Lafifa Jamal 
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/342397291_I_trust_you_more_A_Behavioral_Greeting_Gesture_Study_on_Social_Robots_for_Recommendation_Tasks
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The research hypothesis raises an assumption that a robot with specifically designed greeting gestures, which are close to a user’s native custom, will improve the user’s willingness to trust the robot, compared to robots with ordinary greeting gestures. At the beginning the NAO robot will perform a greeting gesture that is close to the participant’s native custom and the NAO will also speak in the participants’ native language while greeting and recommending an answer. The Wizard-of-Oz Method has been used to respond to participants’ request for an answer recommendation during the experiment. Once the participant asks NAO to help on a specific question, the conductor of the experiment manually controls the NAO robot to recommend an answer and  the conductor also precisely controls the robot to recommend the same answer to a specific question. Under CG conditions the NAO robot will answer in English and under CG condition the NAO robot will answer in the participant’s native language. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The recommendation audio was pre-recorded by native speakers and the acceptance rate was calculated  for each participant, which is the ratio of their accepted recommendations against all of the NAO’s recommendations. The result revealed that an acceptance rate under CG has a significant difference relative to an acceptance rate under NG. Therefore the results showed a positive support to the hypothesis. The result indicated that a close-to-native-custom robot behavior design has a higher validation for the user’s acceptance rate with respect to the robot’s recommendation.
                        </p>
                        <hr>

                        <h3 class="mt-3">Paper Title: A Study on Educational Robots </h3>
                        <H4>Introduction</H4>
                        <p>
                            In this paper,  the STIMEY Robot, an educational robot,  has been introduced, which has been created through participatory design procedures to identify the users’ attitudes after a cross European study where five different countries participated. The robot has been evaluated in real classroom environment with students aged between 13 and 18 years old, who had a STEM lesson with the aid of the robot.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Anna-Maria Velentza, Stavros Ioannidis, Nefeli Georgakopoulou , Mohammad Shidujaman , and Nikolaos Fachantidis.
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/352935312_Educational_Robot_European_Cross-Cultural_Design 
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The total number of participants was 92 and in each school classroom, the researchers conducted one lesson which lasted for two hours with the aid of the STIMEY Platform and Robot prototype. The STIMEY platform and its capabilities were first introduced to the students and the students then completed questionnaires related to their opinions regarding the hypothetical use of a robot during their courses. Then the lesson was implemented utilizing the STIMEY educational Platform, accompanied by the STIMEY Robot which was the tutor of the lesson in collaboration with a teacher with STEM studies expertise. Finally, after the end of the lesson, the students were asked to complete an online questionnaire regarding their Attitudes, Positions, and Behaviors towards STEM and STIMEY robots (STQ). The lesson that the robot taught to the students was about STEM and more specifically about the ‘Dark Side of the Moon’, explaining basic physics and astrophysics principles regarding the lighting conditions of the moon. The lesson was adapted based on their educational level. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The goal of this research was to show as many robot’s features and behaviors during the course about its appearance such as  different facial expressions and usability like  feedback, interconnectivity with the web- platform. The analysis of the STQ was determined by  calculating the Mean Value (MV) and Standard Deviation (SD) for each STQ question. A Kruskal Wallis test was applied  to identify the effect of the students’ demographic characteristics on their attitudes toward STEM studies and STIMEY robot and  a paired-sample t-test was applied to compare the differences in the students’ attitudes before and after having a lesson with the robot. The results showed that robots’ characteristics such as their social behavior have been proven beneficial in educational and teaching tasks by strengthening student’s cognitive and affective outcomes . Educational robots also help students better understand and appreciate STEM studies. 
                        </p>
                    </div>
                    <div id="person3" class="tab-pane fade">
                        <h3>Paper Title: Design of a robot for supporting children attention during long distance   learning </h3>
                        <H4>Introduction</H4>
                        <p>
                            This paper  describes the design process of a robot to support children during long distance learning. A survey was conducted to students, parents and teachers to understand the problem and gather information about the possible use of a robot to support students. The concept of a companion robot for supporting children during online classes was then proposed.The robot’s main function was to increase children’s awareness and attention by monitoring the teacher’s voice and redirecting the student’s attention through expressive behavior.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Dante Arroyo, Yijie Guo1,  Mingyue Yu,  Mohammad Shidujaman, Rodrigo Fernandes
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/345809581_Towards_the_Design_of_a_Robot_for_Supporting_Children's_Attention_During_Long_Distance_Learning 
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The online survey was conducted to participants located in Shanghai. China and a total of 84 junior school students participated in the online survey and also 23 parents and 36 teachers of junior school students also participated in the survey and children were asked how lonely they felt during online classes and how much interesting and motivated they felt during online classes and parents and students were asked how often the students had a distracting behavior and the results of the survey showed that regarding the feeling of isolation, when considering all students together, a neutral mean was obtained and  results suggest that younger children tend to report higher loneliness levels and regarding motivation and interest of onlines, a neutral mean was obtained. Regarding the distracting behaviors in students, students get moderately distracted during online classes.  The results of the survey show students seem to strongly desire a companion during online classes while parents/teachers are neutral or rejective of this idea.
                            Design of Robot: There were some guidelines followed for  the development of a robot for supporting the attention of children in long distance learning. For example, the should be able to redirect the children’s attention to the screen when the teacher is giving the classes and the best way to do this is through body language, as it is a subtle way to transmit information in human-human interaction but the robot can not become a source of distraction as that would affect the development of the online class. The robot is not intended to have direct interaction with the child and the robot must be positioned in the surroundings of the screen where the online class will be displayed so that the the robot should be able to monitor the teacher’s tone of voice without problem, and to be noticed by the child when moving a part of its body to redirect attention. For children to feel comfortable, a  human-like robot can be designed for a friendly appearance.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            According to the results of the survey , it was preferred to have a robot along with students which could help them to maintain attention during classes. Moreover, the researchers have defined the design guidelines for this type of robot  and based on these guidelines, they made a 3D model of the robot along with the considerations for achieving an expressive movement that can redirect children’s attention to the screen. 
                        </p>
                        <hr>

                        <h3 class="mt-3">Paper Title: Design of a Wireless Power Transmission Robot
                        </h3>
                        <H4>Introduction</H4>
                        <p>
                            A mobile robot is equipped with a wireless charger and navigates in the environment of various battery nodes in order to charge the network in an efficient way. The presented research in this paper illustrates design and development of real functional systems with the aim to change the traditional way of carrying the battery to charger into navigating the charger to batteries. The research has been initiated by reviewing the existing wireless power transmission technologies and later on equipped mobile robots with QI standard compatible WPT. 

                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Mohammad Shidujaman, Lenis Tejada Rodriguez, Hooman Samani 
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/281524822_Design_and_Navigation_Prospective_for_Wireless_Power_Transmission_Robot
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            Wireless Power Transmission robot architecture is described into two parts: Robot hardware design and  Software architecture. Robot hardware design consists of its three major parts namely sensors, servo motor and wheels. In this experiment, solo qi wireless charger with USB charger has been used as a wireless power source and a universal receiver is required for the user mobile device that is not capable for wireless charging. The four kinds of sensor  used in our system are Ultrasonic sensor, touch sensor, light sensor and sound sensor. Touch Sensor blocks are used to detect contact with an obstacle whereas light Sensor blocks are used to measure brightness. Sound Sensor blocks are used to measure the sound pressure. Servo Motor blocks are used to control a Servo Motor.  According to the system structure design, the platform is figured as follows which mainly consists of a robot moving body part and wireless charger holding carrier. While the wireless charging robot come closer with the receiver for LG mobile then the mobile started to take charge and shows the signal to the user When the wireless charging robot come to the receiver mobile and touch with the receiver it can take charge and while the battery is in the charging mode it shows the signal to the user that it is charging.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            In this paper , the researchers  have presented a robotic system which is used for the purpose of wireless charging between multiple users where it is possible to use various modes of interaction with multi-modal functionality in practice of daily life. This proposed system where the user is involved with different interactions is mostly designed for indoor use whereas outdoor work functionality will be for the  future work. 
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- paper Review end  -->

    <div class="container card p-3">
        <h2>Why did you select this research title?</h2>
        <p>The title of this research is University Assistant Robo. We can also call it URRO . The goal of this robot is to guide students in learning and thus reduce workload for faculties, staffs. The robo will be designed and created in such a way so that it can provide all information regarding IUB, making the life of IUB students easier. It can help all level of students but the targets will be mostly freshers or students in their first semester as they are new comers and don’t many thing about IUB so the robo can educate the students regarding teaching methods , tips on how to keep CGPA higher , the teaching methods used , regarding how exams are taken, the courses offered at different departments, locations of classrooms, faculty rooms, registrar’s office, admission office etc. </p>

        <h2> How do you connect your research with C and I? </h2>
        <p>Here the robot and the humans are brought close together for the creation of a smart university. Robots will interact with humans and humans will interact with robot and the robot is a machine over here so there are some interaction models involved over here for example HRI (Human to Robot Interaction model) , RHI( Robot to Human Interaction model), Human to Machine Interaction model. In our research, we can observe how the robo interacts with students and how friendly the tone does it use and of course language is an important issue over here. Most students studying here are Bangladeshi by birth and they are most comfortable speaking Bangla around so the robo has to communicate with students, even faculties and staff members with Bangla and it has to maintain a Bengali culture , appearance through the communication.</p>

        <h2 class="">What are the research gaps and problems you have found and how do you plan to solve them?</h2>
        <p>There are some research gaps or problems that we have found . As said before, language is important. We have to use a Virtual Assistant that will answer or question students on what help or information they need. Some well known virtual assistants are Siri  in Apple, Google Assistant, Bixby in Samsung and Alexa Amazon and we have to develop such a virtual assistant so  that the virtual assistant can communicate with humans via text and voice in Bangla. We have to also design a robot that looks friendlier to students so that no becomes scared and we have to design it in a way, keeping in mind with the bengali culture so we can think of the flag of Bangladesh that has green and red color and keeping that we can color the robot to enhance it at a cultural level and also what the body will be made of. Of course, it's a machine so we will metal but other parts for movement and weight flexibility, wood can be used. The robot that will be made should be mobile so that it can accompany students to show them locations. We can use wheels for mobility instead of just preferring to keep the robot at the IUB reception area. </p>

    </div>

    <!-- Team -->
    <div class="team-boxed">
        <div class="container">
            <div class="intro">
                <h2 class="text-center" id="team">Team </h2>
                <p class="text-center">Our teams information</p>
            </div>
            <div class="row people">
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="https://avatars.githubusercontent.com/u/67865591?s=400&u=785391cd9333c3ef4b9e37030b36ed54c960a773&v=4">
                        <h3 class="name">Md Nakibul Islam</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href="#"><i class="fa-brands fa-linkedin"></i></a><a href="#"><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="https://scontent.fdac136-1.fna.fbcdn.net/v/t39.30808-1/361972745_2027129770963741_818507219456520854_n.jpg?stp=dst-jpg_s320x320&_nc_cat=101&ccb=1-7&_nc_sid=fe8171&_nc_eui2=AeE3UhtbEIyI-lw96uZy2QfPbOizYcYBxths6LNhxgHG2Cr_tWjNQBsbrHdujebFfEZD3pjX-J_m0UNnLFHvryMA&_nc_ohc=48UMy18bAwYAX_Rifl9&_nc_ht=scontent.fdac136-1.fna&oh=00_AfCy9xkrR3tgd8VGlHYj0RVnEyH_7N3rUky8QNVSE9QlAA&oe=6525B90B">
                        <h3 class="name">Refat Ahmed</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href="https://www.linkedin.com/in/nakibulislam00/"><i class="fa-brands fa-linkedin"></i></a><a href="https://www.researchgate.net/profile/Md-Islam-1997"><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="img/357440071_147007135065605_1231062325034910102_n.jpg">
                        <h3 class="name">Rose Chowdhury Ritu</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href="https://www.linkedin.com/in/rose-chowdhury-ritu-2539601b7/?fbclid=IwAR3AnzKvuWd_XtfIZQKN81JRte2iNdkhptwBoT4emsNkK9usK0A9W4EDLBw"><i class="fa-brands fa-linkedin"></i></a><a href="https://www.researchgate.net/profile/Rose-Ritu?fbclid=IwAR0xAmDCJX-ZNNGzMT8y8Y4gemM4P8M3Oi1ZnJo0gVUYlW2FhyA8wHP9_yU"><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.bundle.min.js"></script>    
    <!-- End team -->

</body>
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
</html>
