<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>URRO</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
    <link rel="stylesheet" href="style.css">

</head>
<body style="background-color: #eef4f7;">
    <!-- nav start -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light fixed-top">
        <a class="navbar-brand" href="#">URRO</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse justify-content-center font-weight-bold" id="navbarNav">
        <ul class="navbar-nav">
            <li class="nav-item">
            <a class="nav-link" href="#home">Home </a>
            </li>
            <li class="nav-item">
            <a class="nav-link" href="#Project_Details">Project Details</a>
            </li>
            <li class="nav-item">
            <a class="nav-link" href="#Paper_Review">Project work</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" href="#team">Team</a>
            </li>
        </ul>
        </div>
    </nav>
    <!-- nav end  -->
    <h1 class="text-center mb-5" id="home">/h1>
    <!-- home carousel start -->
    <div class="text-center pt-5 pb-2" id="home">
        <h1>Wealcome</h1>
    </div>
<div class="container">
    <div id="carouselExampleIndicators" class="carousel slide" data-ride="carousel">
        <ol class="carousel-indicators">
            <li data-target="#carouselExampleIndicators" data-slide-to="0" class="active"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="1"></li>
            <li data-target="#carouselExampleIndicators" data-slide-to="2"></li>
        </ol>
        <div class="carousel-inner">
            <div class="carousel-item active">
                <img src="https://images.unsplash.com/photo-1485827404703-89b55fcc595e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2070&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
            <div class="carousel-item">
                <img src="https://images.unsplash.com/photo-1563968743333-044cef800494?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1958&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
            <div class="carousel-item">
                <img src="https://images.unsplash.com/photo-1518314916381-77a37c2a49ae?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2071&q=80" style="height: 600px; width: 100%;" alt="...">
            </div>
        </div>
        <a class="carousel-control-prev" href="#carouselExampleIndicators" role="button" data-slide="prev">
            <span class="carousel-control-prev-icon" aria-hidden="true"></span>
            <span class="sr-only">Previous</span>
        </a>
        <a class="carousel-control-next" href="#carouselExampleIndicators" role="button" data-slide="next">
            <span class="carousel-control-next-icon" aria-hidden="true"></span>
            <span class="sr-only">Next</span>
        </a>
    </div>
</div>
    <!-- home carousel end -->
    <!-- project Details  -->
    <div class=" mt-5" id="Project_Details">
        <h1 >Project Details</h1>
    </div>
    <div class="container mt-5 mb-5 project-details">
        <div class="row">
        <div class="col-sm-6">
            <h1>Representative Assistant Robo</h1>
            <p>
                Introducing our cutting-edge University Assistant Robot, designed to streamline and enhance the student experience on campus. This innovative robot is equipped with a vast array of knowledge about the university's infrastructure and resources. <br>

                Need directions to the BC building, registration office, library, or any other key location? Our robot has you covered. Simply ask, and it will promptly provide clear and accurate directions. <br>
                
                Looking for information about clubs, labs, or financial applications? Our robot is a treasure trove of data, ready to share details about the vibrant club scene, state-of-the-art labs, and the seamless financial process. <br>
                
                Worried about missing the semester fee deadline? Our robot will keep you informed about important dates, ensuring you never miss a deadline. <br>
                
                With its friendly interface and comprehensive knowledge base, the University Assistant Robot is here to make your university journey smoother and more informed. Ask away, and let the robot guide you through your academic adventure.
            </p>
        </div>
        <div class="col-sm-6">
            <img src="img\Firefly Background university campus , a girl talk with robot 82537.jpg" style="width: 100%; height: 100%;" alt="">
        </div>
        </div>
    </div>
    <!-- project Details End-->

    <!-- paper Review Start  -->
    <div class="text-center mt-5 pb-3" id="Paper_Review">
        <h1>Project work</h1>
    </div>

    <!-- porject proposal -->
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text">
                <h2>Week 1</h2>
                <h5 class="text-center">Project proposal: URRO Voice Assistant</h5>
                <div class="row">
                    <div class="col">
                        <h5>Project Summary</h5>
                        <p>URRO is a voice assistant robot designed to help students at Independent University, Bangladesh. The robot is equipped to answer questions related to the university, making it a valuable resource for students.</p>
        
                        <h5>Features</h5>
                        <ul class="system-blding">
                            <li>Campus Navigation: URRO can provide directions to various locations within the university, such as rooms, buildings, the VC office, and the registrar's office.</li>
                            <li>University Information: You can ask URRO for details about university departments, clubs, labs, and financial discounts.</li>
                            <li>Image Processing: URRO uses image processing to identify the person asking a question, enabling more personalized responses.</li>
                        </ul>
        
                        <h5>Benefits</h5>
                        <ul class="system-blding">
                            <li>URRO will provide students with a convenient and easy-to-use way to access information about the university.</li>
                            <li>URRO will help students to navigate the campus more easily.</li>
                            <li>URRO will provide students with a personalized and engaging way to interact with the university.</li>
                        </ul>
        
                        <h5>Project Goals</h5>
                        <p>The goals of this project are to:</p>
                        <ul class="system-blding">
                            <li>Develop a fully functional voice assistant robot that can answer questions about Independent University, Bangladesh.</li>
                            <li>Integrate image processing into the robot to enable personalized responses.</li>
                            <li>Deploy the robot on campus for student use.</li>
                        </ul>
        
                        <!-- <h5>Project Timeline</h5>
                        <p>The project will be completed in three phases:</p>
                        <ul class="system-blding">
                            <li>Phase 1 (3 months): Develop a prototype of the voice assistant robot.</li>
                            <li>Phase 2 (3 months): Integrate image processing into the robot.</li>
                            <li>Phase 3 (3 months): Deploy the robot on campus for student use.</li>
                        </ul> -->
        
                        <!-- <h5>Project Budget</h5>
                        <p>The total budget for this project is $100,000. This budget will cover the costs of hardware, software, and development.</p> -->
        
                        <h5>Conclusion</h5>
                        <p>URRO Voice Assistant has the potential to be a valuable resource for students at Independent University, Bangladesh. The robot will provide students with a convenient and easy-to-use way to access information about the university, navigate the campus, and interact with the university in a personalized way. We believe that URRO will be a valuable addition to the Independent University, Bangladesh community.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text">
                <h2>Week 2</h2>  
                <h4 class="text-center">Paper Review</h4>  
                <button type="button" class="collapsible">Md Nakibul Islam</button>
                <div class="content">
                    <div id="person3">
                        <h3>Paper Title: Design of a robot for supporting children attention during long distance   learning </h3>
                        <H4>Introduction</H4>
                        <p>
                            This paper  describes the design process of a robot to support children during long distance learning. A survey was conducted to students, parents and teachers to understand the problem and gather information about the possible use of a robot to support students. The concept of a companion robot for supporting children during online classes was then proposed.The robot’s main function was to increase children’s awareness and attention by monitoring the teacher’s voice and redirecting the student’s attention through expressive behavior.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Dante Arroyo, Yijie Guo1,  Mingyue Yu,  Mohammad Shidujaman, Rodrigo Fernandes
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/345809581_Towards_the_Design_of_a_Robot_for_Supporting_Children's_Attention_During_Long_Distance_Learning 
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The online survey was conducted to participants located in Shanghai. China and a total of 84 junior school students participated in the online survey and also 23 parents and 36 teachers of junior school students also participated in the survey and children were asked how lonely they felt during online classes and how much interesting and motivated they felt during online classes and parents and students were asked how often the students had a distracting behavior and the results of the survey showed that regarding the feeling of isolation, when considering all students together, a neutral mean was obtained and  results suggest that younger children tend to report higher loneliness levels and regarding motivation and interest of onlines, a neutral mean was obtained. Regarding the distracting behaviors in students, students get moderately distracted during online classes.  The results of the survey show students seem to strongly desire a companion during online classes while parents/teachers are neutral or rejective of this idea.
                            Design of Robot: There were some guidelines followed for  the development of a robot for supporting the attention of children in long distance learning. For example, the should be able to redirect the children’s attention to the screen when the teacher is giving the classes and the best way to do this is through body language, as it is a subtle way to transmit information in human-human interaction but the robot can not become a source of distraction as that would affect the development of the online class. The robot is not intended to have direct interaction with the child and the robot must be positioned in the surroundings of the screen where the online class will be displayed so that the the robot should be able to monitor the teacher’s tone of voice without problem, and to be noticed by the child when moving a part of its body to redirect attention. For children to feel comfortable, a  human-like robot can be designed for a friendly appearance.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            According to the results of the survey , it was preferred to have a robot along with students which could help them to maintain attention during classes. Moreover, the researchers have defined the design guidelines for this type of robot  and based on these guidelines, they made a 3D model of the robot along with the considerations for achieving an expressive movement that can redirect children’s attention to the screen. 
                        </p>
                        <hr>

                        <h3 class="mt-3">Paper Title: Design of a Wireless Power Transmission Robot
                        </h3>
                        <H4>Introduction</H4>
                        <p>
                            A mobile robot is equipped with a wireless charger and navigates in the environment of various battery nodes in order to charge the network in an efficient way. The presented research in this paper illustrates design and development of real functional systems with the aim to change the traditional way of carrying the battery to charger into navigating the charger to batteries. The research has been initiated by reviewing the existing wireless power transmission technologies and later on equipped mobile robots with QI standard compatible WPT. 

                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Mohammad Shidujaman, Lenis Tejada Rodriguez, Hooman Samani 
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/281524822_Design_and_Navigation_Prospective_for_Wireless_Power_Transmission_Robot
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            Wireless Power Transmission robot architecture is described into two parts: Robot hardware design and  Software architecture. Robot hardware design consists of its three major parts namely sensors, servo motor and wheels. In this experiment, solo qi wireless charger with USB charger has been used as a wireless power source and a universal receiver is required for the user mobile device that is not capable for wireless charging. The four kinds of sensor  used in our system are Ultrasonic sensor, touch sensor, light sensor and sound sensor. Touch Sensor blocks are used to detect contact with an obstacle whereas light Sensor blocks are used to measure brightness. Sound Sensor blocks are used to measure the sound pressure. Servo Motor blocks are used to control a Servo Motor.  According to the system structure design, the platform is figured as follows which mainly consists of a robot moving body part and wireless charger holding carrier. While the wireless charging robot come closer with the receiver for LG mobile then the mobile started to take charge and shows the signal to the user When the wireless charging robot come to the receiver mobile and touch with the receiver it can take charge and while the battery is in the charging mode it shows the signal to the user that it is charging.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            In this paper , the researchers  have presented a robotic system which is used for the purpose of wireless charging between multiple users where it is possible to use various modes of interaction with multi-modal functionality in practice of daily life. This proposed system where the user is involved with different interactions is mostly designed for indoor use whereas outdoor work functionality will be for the  future work. 
                        </p>
                    </div>
                </div>
                <button type="button" class="collapsible">Rose Chowdhury Ritu</button>
                <div class="content">
                    <div id="person2">
                        <h3>Paper Title:  A study on the Behavioral Gesture of Social Robots.</h3>
                        <H4>Introduction</H4>
                        <p>
                            This research designed  four different greeting gestures for the NAO robot based on human’s greeting custom and conducted a user experiment in which participants from different countries interact with the robot for a designated recommendation task and the research investigated how cultural familiarity affects acceptance of an agent’s recommendation. 20 participants from four different countries, China, Bangladesh, Japan and Thailand , participated in the experiment. 
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Mohammad Shidujaman,  Haipeng Mi, Lafifa Jamal 
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/342397291_I_trust_you_more_A_Behavioral_Greeting_Gesture_Study_on_Social_Robots_for_Recommendation_Tasks
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The research hypothesis raises an assumption that a robot with specifically designed greeting gestures, which are close to a user’s native custom, will improve the user’s willingness to trust the robot, compared to robots with ordinary greeting gestures. At the beginning the NAO robot will perform a greeting gesture that is close to the participant’s native custom and the NAO will also speak in the participants’ native language while greeting and recommending an answer. The Wizard-of-Oz Method has been used to respond to participants’ request for an answer recommendation during the experiment. Once the participant asks NAO to help on a specific question, the conductor of the experiment manually controls the NAO robot to recommend an answer and  the conductor also precisely controls the robot to recommend the same answer to a specific question. Under CG conditions the NAO robot will answer in English and under CG condition the NAO robot will answer in the participant’s native language. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The recommendation audio was pre-recorded by native speakers and the acceptance rate was calculated  for each participant, which is the ratio of their accepted recommendations against all of the NAO’s recommendations. The result revealed that an acceptance rate under CG has a significant difference relative to an acceptance rate under NG. Therefore the results showed a positive support to the hypothesis. The result indicated that a close-to-native-custom robot behavior design has a higher validation for the user’s acceptance rate with respect to the robot’s recommendation.
                        </p>
                        <hr>

                        <h3 class="mt-3">Paper Title: A Study on Educational Robots </h3>
                        <H4>Introduction</H4>
                        <p>
                            In this paper,  the STIMEY Robot, an educational robot,  has been introduced, which has been created through participatory design procedures to identify the users’ attitudes after a cross European study where five different countries participated. The robot has been evaluated in real classroom environment with students aged between 13 and 18 years old, who had a STEM lesson with the aid of the robot.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Anna-Maria Velentza, Stavros Ioannidis, Nefeli Georgakopoulou , Mohammad Shidujaman , and Nikolaos Fachantidis.
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/352935312_Educational_Robot_European_Cross-Cultural_Design 
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The total number of participants was 92 and in each school classroom, the researchers conducted one lesson which lasted for two hours with the aid of the STIMEY Platform and Robot prototype. The STIMEY platform and its capabilities were first introduced to the students and the students then completed questionnaires related to their opinions regarding the hypothetical use of a robot during their courses. Then the lesson was implemented utilizing the STIMEY educational Platform, accompanied by the STIMEY Robot which was the tutor of the lesson in collaboration with a teacher with STEM studies expertise. Finally, after the end of the lesson, the students were asked to complete an online questionnaire regarding their Attitudes, Positions, and Behaviors towards STEM and STIMEY robots (STQ). The lesson that the robot taught to the students was about STEM and more specifically about the ‘Dark Side of the Moon’, explaining basic physics and astrophysics principles regarding the lighting conditions of the moon. The lesson was adapted based on their educational level. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The goal of this research was to show as many robot’s features and behaviors during the course about its appearance such as  different facial expressions and usability like  feedback, interconnectivity with the web- platform. The analysis of the STQ was determined by  calculating the Mean Value (MV) and Standard Deviation (SD) for each STQ question. A Kruskal Wallis test was applied  to identify the effect of the students’ demographic characteristics on their attitudes toward STEM studies and STIMEY robot and  a paired-sample t-test was applied to compare the differences in the students’ attitudes before and after having a lesson with the robot. The results showed that robots’ characteristics such as their social behavior have been proven beneficial in educational and teaching tasks by strengthening student’s cognitive and affective outcomes . Educational robots also help students better understand and appreciate STEM studies. 
                        </p>
                    </div>
                </div>
                <button type="button" class="collapsible">REFAT AHMED BHUIYAN</button>
                <div class="content">
                    <div id="person1">
                        <h3>Paper Title: Kinematics Analysis of a quadruped robot</h3>
                        <H4>Introduction</H4>
                        <p>
                            In this study, there are mathematical derivations provided  for forward and Inverse kinematics to determine the robots' positions and joint angles briefly. In this study, the researchers have analyzed and derived the forward and inverse kinematics of the quadruped robots and verified their correlation using Python Programming and Pybullet Physics to determine the robot’s leg motion.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>Md.Hasibur Rahman,  Md.Mazharul Islam, Md.Fayed Al Monir, Saadia Binte Alam,  Ruzvelt, Md.Mijanur Rahman, Rubaiyat Islam.</p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/361466674_Kinematics_analysis_of_a_quadruped_robot_Simulation_and_Evaluation "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            A quadruped robot consists of four legs with a rigid body where each leg has three degrees of freedom and there are three joints : coxa joint, femur joint, and tibia joint. The frame-to-frame rotation and translation matrices are solved to find the forward kinematics in order to achieve the end-effector positions. Inverse kinematics gives the different joint angles of the quadruped robot leg and the end effectors value are used to determine the joint angles.
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            After deriving the forward kinematics and inverse kinematics, the correlation between them was verified using mathematical coding in python and Pybullet Physics engines and an algorithm in python was developed where joint angle values are used to get the end effector values and the goal of the paper is successfully achieved by deriving the kinematic equation for the quadruped robot which defines the position, orientation, and movement of the robot.
                        </p>
                        <hr>
                        <h3>Paper Title: Analysis of a Smart Bag Reminder System</h3>
                        <H4 class="mt-3">Introduction</H4>
                        <p>
                            It is important to keep track of many details when caring for a newborn such as making sure to pack all necessary items when leaving the house with a newborn. This paper showed a light-feedback reminder bag and a light-sound feedback reminder bag that use a pressure sensor to remind parents when anything is missing from the bag. A user study with 13 participants was conducted with these two reminder bags.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Md Farhad Hossain, Mengru Xue, Yuqi Hu,  Mohammad Shidujaman.
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/372224060_Design_and_Performance_Analysis_of_a_Smart_Bag_Reminder_System_for_Parents
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <p>
                            The system works by using an Arduino installing a pressure sensor module, an LED light in each of the bag’s pockets, and a speaker and along with the different light feedback from different pockets, the speaker also gives different sound feedback. As soon as the pressure sensor determines that objects have been pushed against it, the light and sound feedback will become active. The bag uses a modular pressure sensor that is readily detachable, and parents can choose the number of pockets that can be utilized and , the audio feedback can be customized according to their preferences, and they can label the front of each pocket with the items they use most often. 
                        </p>
                        <h4 class="mt-3">Conclusion</h4>
                        <p>
                            The result of this research showed that the light-sound feedback facilitates parent reminders better than light feedback. The largest number of participants displayed enjoyment of the task with a light-sound prototype through the use of a smile. The parents realized that  it was a sound feedback with light, and that when they packaged things, the audio feedback related to the items was delivered when they were packaging and so the  sound feedback helped them move more quickly and  receiving sound feedback assisted them in recognizing what they were packing as  they didn’t have to double-check what they put in the bag since the sound feedback helped them identify the items
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- paper Review end  -->

    <!-- Why do we select week 3 -->
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text">
                <h2>Week 3</h2>
        <h4 class="text-center">Research gap of other papers</h4>
        <h2>Why did you select this research title?</h2>
        <p>The title of this research is University Assistant Robo. We can also call it URRO . The goal of this robot is to guide students in learning and thus reduce workload for faculties, staffs. The robo will be designed and created in such a way so that it can provide all information regarding IUB, making the life of IUB students easier. It can help all level of students but the targets will be mostly freshers or students in their first semester as they are new comers and don’t many thing about IUB so the robo can educate the students regarding teaching methods , tips on how to keep CGPA higher , the teaching methods used , regarding how exams are taken, the courses offered at different departments, locations of classrooms, faculty rooms, registrar’s office, admission office etc. </p>

        <h2> How do you connect your research with C and I? </h2>
        <p>Here the robot and the humans are brought close together for the creation of a smart university. Robots will interact with humans and humans will interact with robot and the robot is a machine over here so there are some interaction models involved over here for example HRI (Human to Robot Interaction model) , RHI( Robot to Human Interaction model), Human to Machine Interaction model. In our research, we can observe how the robo interacts with students and how friendly the tone does it use and of course language is an important issue over here. Most students studying here are Bangladeshi by birth and they are most comfortable speaking Bangla around so the robo has to communicate with students, even faculties and staff members with Bangla and it has to maintain a Bengali culture , appearance through the communication.</p>

        <h2 class="">What are the research gaps and problems you have found and how do you plan to solve them?</h2>
        <p>There are some research gaps or problems that we have found . As said before, language is important. We have to use a Virtual Assistant that will answer or question students on what help or information they need. Some well known virtual assistants are Siri  in Apple, Google Assistant, Bixby in Samsung and Alexa Amazon and we have to develop such a virtual assistant so  that the virtual assistant can communicate with humans via text and voice in Bangla. We have to also design a robot that looks friendlier to students so that no becomes scared and we have to design it in a way, keeping in mind with the bengali culture so we can think of the flag of Bangladesh that has green and red color and keeping that we can color the robot to enhance it at a cultural level and also what the body will be made of. Of course, it's a machine so we will metal but other parts for movement and weight flexibility, wood can be used. The robot that will be made should be mobile so that it can accompany students to show them locations. We can use wheels for mobility instead of just preferring to keep the robot at the IUB reception area. </p>

        <div class="row">
            <div class="col-sm-6">
                <h3>Testing</h3> 
                <br>
                <p>Teasting code of the project, how it's working.</p>
                <div class="card">
                    <img src="img\test video 1.PNG" alt="">
                    <div class="card-body">
                        <p class="card-text">First testing of the robot code. <a href="https://youtube.com/shorts/uQ5nPS791ZI?feature=share">Play</a></p>
                    </div>
                </div>
            </div>
            <div class="col-sm-6">
                <h3>Design</h3>
                <p>Scratch design of the robot for the reference.</p>
                <div class="card" >
                    <img src="img\CamScanner 10-15-2023 20.28.jpg" class="card-img-top" alt="...">
                    <div class="card-body">
                        <p class="card-text">First scratch of the robot.</p>
                    </div>
                </div>
            </div>
        </div>
            </div>
        </div>
    </div>

    <!-- Week 4 -->
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text">
                <h1>Week 4</h1>
                <button type="button" class="collapsible">Paper Review's</button>
                <div class="content">
                    <div id="person3">
                        <h3>AI-Powered University: Design and Deployment of Robot Assistant for Smart Universities 
                        </H4>
                        <p>
                            This research presents four robot systems that utilize artificial intelligence techniques to assist students, teachers, and staff in the university. Physical robots are used in the classroom to enhance student engagement, learning experiences, and outcomes. Recent advances in robotic research enable the robot to assist humans in many ways. 
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Thanh-Hiep Nguyen, Duy-Nhat Tran, Doan-Linh Vo, Van-Hung Mai, and Xuan-Quy Dao
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/profile/Dao-Xuan-Quy/publication/369687154_jaitpdf/data/6427656466f8522c38e95b07/jait.pdf
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    The goal of the assist robot systems is to reduce workload and enhance the effect in teaching and learning as well as improve the learning environment at university. The four robot systems including virtual assistant, telepresence, guide, and delivery robots were proposed and developed. The virtual assistant robot supports students and teachers in learning and teaching by an interactive and informative learning environment and consequently maximizing learning outcomes. The telepresence robot allows students to follow the classroom at home or hospital in the case that students are unable to attend classes due to special reasons (Covid-19 pandemic, illness). The guide robot was developed as a physical robot which places or moves in the small range at the library, administrative building, restaurant, and residence to provide information such as book searching, freshman quiz, restaurant menu, events, and places. Finally, the delivery robot aims to deliver documents, books, and food/drink to students and teachers on the university campus in the motive of improving the quality of life and services.
                                </p>
                            </div>
                            <div class="col-sm-4">
                                <img src="img\paper img\re1.PNG" style="width: 100%; height: 100%;" alt="">
                            </div>
                        </div>
                        <h4 class="mt-3">Conclusion</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    The robot systems were built to improve the learning environment as well as fight against COVID-19 pandemic. The AI results showed that  robot systems enhance the quality of life and services in university campuses. The experimental results showed that the approach used is an effective way to guarantee learning environment in COVID-19 pandemic as well as bring a good learning experience
                                </p>
                            </div>
                            <div class="col-sm-4">
                                <img src="img\paper img\re2.PNG" style="width: 100%; height: 100%;" alt="">
                            </div>
                        </div>
                        <hr>
                    </div>
                    <div id="person3">
                        <h3>Influence of the NAO robot as a teaching assistant on university students’ vocabulary learning and attitudes 
                        </H4>
                        <p>
                            A sufficient command of vocabulary is an important component of any language, enabling people to communicate. In other words, communicating in a particular language is almost impossible without sufficient lexical knowledge, which involves receptive and productive aspects of words. Vocabulary has gained more prominence as we have come to know more about its nature and behavior as an outcome of the employment of the computer in language data analysis.
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Hossein Banaeian, Ilkay Gilanlioglu
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://ajet.org.au/index.php/AJET/article/view/6130
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    This research investigated how the NAO robot as a teaching assistant affects the way university students learn vocabulary and their attitudes towards it. A mixed method approach was followed to gather both quantitative and qualitative data. A quasi-experimental design, including a pre-test and a post-test, was employed to explore the impact of the NAO robot on students’ vocabulary learning. Moreover, a questionnaire and an interview were used to identify the attitudes of the participants towards the NAO robot.
                                </p>
                            </div>
                            <div class="col-sm-4">
                                <img src="img\paper img\re3.PNG" style="width: 100%; height: 100%;" alt="">
                            </div>
                        </div>
                        <h4 class="mt-3">Conclusion</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    Descriptive data analysis showed that most of the students liked the NAO robot and its abilities. However, related findings from the qualitative data were mixed. Most participants liked the NAO robot and thought that the robot helped them to learn the new words, while some thought that the technology needed to be improved. 
                                </p>
                            </div>
                        </div>
                        <hr>
                    </div>
                    <div id="person3">
                        <h3> PAINTIQUE: Design and Development of Interaction Model of a Line Following Spray-Painting Robot 
                        </H4>
                        <p>
                            Robots are used nowadays to perform repetitive and risky tasks. It can perform tasks more efficiently and save both time and money. In this modern time of global warming and environmental pollution, using robots leads us to the way to sustainable green development
                        </p>
                        <h4 class="mt-3">Author</h4>
                        <p>
                            Zerin Tasnim, Farhad Ahmed, Zarin Tasnim, Mohammad Shidujaman , and Salah Uddin Ahmed
                        </p>
                        <h4 class="mt-3">Paper link</h4>
                        <a href="https://www.researchgate.net/publication/372303675_PAINTIQUE_Design_and_Development_of_Interaction_Model_of_a_Line_Following_Spray-Painting_Robot
                        "><p>Click here</p></a>
                        <h4 class="mt-3">Summary</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    In this research , the Line Following method is used to create an autonomous mobile robot with two distinct features: line-following and spray painting. It also shows the interaction with lines and walls by the robot. The plan is to minimize the need for humans to manually paint high-rise buildings. The robot is equipped with infrared (IR) sensors that help the robot to detect the path. The spray nozzle is moved by a servo motor as the wall is painted. The Arduino Uno board serves as the robot’s primary controller and powers the entire project.
                                </p>
                            </div>
                            <div class="col-sm-4">
                                <img src="img\paper img\re4.PNG" style="width: 100%; height: 100%;" alt="">
                            </div>
                        </div>
                        <h4 class="mt-3">Conclusion</h4>
                        <div class="row">
                            <div class="col-sm-8">
                                <p>
                                    The robot’s performance is evaluated to ensure that it follows the line correctly and smoothly without drifting off path. Experiments are conducted on the design to find the optimum design, control, and programming for the robots’ best performance and  based on the outcomes, the robot was successful in completing the tasks assigned to it.
                                </p>
                            </div>
                        </div>
                        <hr>
                        <a href="https://docs.google.com/document/d/1C09fw41qcRdce6hliVeN17eVaOdyp8UMfTNmO2FB0gk/edit?usp=sharing"><h4>see more</h4></a>
                    </div>
                </div>
                <!-- Draft paper -->
                <div class="d-grid gap-2 col-6 mx-auto button-text">
                    <a href="https://docs.google.com/document/d/1jz8z7SQzIcvgP-IMv1BrqE-OYZOPeQgivqRNtvuhQk4/edit?usp=sharing"><button type="button" class="btn btn-primary">Draft paper: 1</button></a>
                </div>
                <div class="row">
                    <!-- system bulding -->
                    <div class="col-sm-6">
                        <div class="mt-3 system-blding">
                            <h3 class="text-center">System bulding update</h3>
                            <p>This data set includes information on the following:</p>
                            <ol class="list-group list-group-numbered">
                                <li class="list-group-item">Admission</li>
                                <li class="list-group-item">School</li>
                                <li class="list-group-item">Departments</li>
                                <li class="list-group-item">Clubs</li>
                                <li class="list-group-item">Financial discounts</li>
                                <li class="list-group-item">Labs</li>
                            </ol>
                            <p>The data set is being continuously updated.</p>
                            <p>A sample of the work can be found on GitHub: <a href="https://github.com/Nakib00/Voice-Assistant-URRO.git">https://github.com/Nakib00/Voice-Assistant-URRO.git</a></p>
                        </div>
                    </div>
                <!-- sketch -->
                <div class="col-sm-6">
                    <div class="m-3 system-blding">
                        <h3 class="text-center">Sketch of URRO</h3>
                        <p>Teasting code of the project, how it's working.</p>
                        <div class="card">
                            <img src="img\working\URRO Design.png" style="width: 500px;" alt="">
                        </div>
                    </div>
                </div>
                </div>
            </div>
        </div>
    </div>

    <!-- week 5 -->
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text week5">
                <h1>Week 5</h1>
                <div class="container">
                    <h3 class="mt-3">Equpment List</h3>
                    <ol class="list-group list-group-numbered mt-2 mb-4">
                        <li class="list-group-item">Raspberry Pi</li>
                        <li class="list-group-item">Memory card</li>
                        <li class="list-group-item">Microphone</li>
                        <li class="list-group-item">Speaker</li>
                        <li class="list-group-item">Mini display </li>
                        <li class="list-group-item">Servo motor</li>
                        <li class="list-group-item">Hard board</li>
                    </ol>

                    <h3 class="mt-3">Working Memories</h3>
                    <div class="row">
                        <div class="card col-sm-6 week-5-card">
                            <img src="img/working/w1.jpg" class="card-img-top" alt="...">
                            <div class="card-body">
                              <p class="card-text">Raspberry pi configuration setup.</p>
                            </div>
                        </div>
                        <div class="card col-sm-6 week-5-card">
                            <img src="img/working/w2.jpg" class="card-img-top" alt="...">
                            <div class="card-body">
                              <p class="card-text">Upload code to the respberry pi and fixing error.</p>
                            </div>
                        </div>
                    </div>

                    <h3 class="mt-4">Block diagram</h3>
                    <div class="row">
                        <div class="card col-sm-6">
                            <img src="img\Block diagram\block digram.jpg" class="card-img-top" alt="...">
                            <div class="card-body">
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- week 6 -->
    <div class="pt-2 pb-5 container">
        <div class="row bg-white py-4" style="border-radius: 10px;">
            <div class="col-sm-12 button-text">
                <h2>Week 6</h2>
                <div class="row">
                    <div class="col-sm-6">
                        <button type="button" class="collapsible">System Design</button>
                        <div class="content mt-3">
                            <div id="person3">
                                <img src="img/robo_design.png" style="width: 100%;" height="350px" alt="">
                            </div>
                        </div>
                    </div>

                    <div class="col-sm-6">
                        <button type="button" class="collapsible">Software Simulation</button>
                        <div class="content mt-3">
                            <div id="person2">
                                <div class="embed-responsive embed-responsive-16by9">
                                    <iframe class="embed-responsive-item" src="https://www.youtube.com/watch?v=xmzDt16ANE8" allowfullscreen></iframe>
                                </div>
                                <a href="https://www.youtube.com/watch?v=xmzDt16ANE8" class="btn btn-info" role="button">Simulation Video</a>
                            </div>
                        </div>
                    </div>

                    <div class="col-sm-3">
                    </div>

                    <div class="col-sm-6">
                        <button type="button" class="collapsible">Hardware Assembly</button>
                        <div class="content mt-3">
                            <div id="person2">
                                <div class="row">
                                    <div class="col-sm-6">
                                        <img src="img/demo.jpg" style="width: 100%;" height="350px" alt="">
                                    </div>
                                    <div class="col-sm-6">
                                        <img src="img/online_demo.png" style="width: 100%;" height="350px" alt="">
                                    </div>
                                </div>

                                
                                <br>
                                
                            </div>
                        </div>
                    </div>

                    <div class="col-sm-3">
                    </div>

                </div>  
            </div>
        </div>
    </div>

    <!-- Team -->
    <div class="team-boxed">
        <div class="container">
            <div class="intro">
                <h2 class="text-center" id="team">Team </h2>
                <p class="text-center">Our teams information</p>
            </div>
            <div class="row people">
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="https://avatars.githubusercontent.com/u/67865591?s=400&u=785391cd9333c3ef4b9e37030b36ed54c960a773&v=4">
                        <h3 class="name">Md Nakibul Islam</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href="https://www.linkedin.com/in/nakibulislam00/"><i class="fa-brands fa-linkedin"></i></a><a href="https://www.researchgate.net/profile/Md-Islam-1997"><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="https://avatars.githubusercontent.com/u/104460180?v=4">
                        <h3 class="name">Refat Ahmed</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href=""><i class="fa-brands fa-linkedin"></i></a><a href=""><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
                <div class="col-md-6 col-lg-4 item">
                    <div class="box"><img class="rounded-circle" src="img/357440071_147007135065605_1231062325034910102_n.jpg">
                        <h3 class="name">Rose Chowdhury Ritu</h3>
                        <!-- <p class="description">Aenean tortor est, vulputate quis leo in, vehicula rhoncus lacus. Praesent aliquam in tellus eu gravida. Aliquam varius finibus est, et interdum justo suscipit id. Etiam dictum feugiat tellus, a semper massa. </p> -->
                        <div class="social"><a href="#"><i class="fa-brands fa-facebook"></i></a><a href="https://www.linkedin.com/in/rose-chowdhury-ritu-2539601b7/?fbclid=IwAR3AnzKvuWd_XtfIZQKN81JRte2iNdkhptwBoT4emsNkK9usK0A9W4EDLBw"><i class="fa-brands fa-linkedin"></i></a><a href="https://www.researchgate.net/profile/Rose-Ritu?fbclid=IwAR0xAmDCJX-ZNNGzMT8y8Y4gemM4P8M3Oi1ZnJo0gVUYlW2FhyA8wHP9_yU"><i class="fa-brands fa-researchgate"></i></a></div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.bundle.min.js"></script>    
    <!-- End team -->

</body>
<script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx" crossorigin="anonymous"></script>
<script src="script.js"></script>
</html>
